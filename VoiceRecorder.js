// VoiceRecorder.js

import React, { useEffect, useRef, useState } from 'react';

import { View, Text, TouchableOpacity, FlatList, Alert, StyleSheet, ActivityIndicator, TextInput, ScrollView } from 'react-native';

import { Audio } from 'expo-av';

import { supabase } from './supabaseClient';

import { transcribeAudio } from './services/transcriptionService';

import { analyzeNote } from './services/quoteAnalysisService';

import { useAppStore } from './store/useAppStore';

import { generateQuoteFromTranscription } from './utils/ai_quote_generator';

import { insertAutoQuote } from './utils/supabase_helpers';

import { handleAPIError } from './utils/errorHandler';

import logger from './utils/logger';
import { showSuccess, showError } from './components/Toast';

export default function VoiceRecorder({ projectId }) {

  const [recording, setRecording] = useState(null);

  const [recordUri, setRecordUri] = useState(null);

  const [durationMs, setDurationMs] = useState(0);

  const [uploading, setUploading] = useState(false);

  const [transcription, setTranscription] = useState('');

  const [items, setItems] = useState([]);

  const soundRef = useRef(null);

  const [playingId, setPlayingId] = useState(null);

  const [editingId, setEditingId] = useState(null);

  const [editText, setEditText] = useState('');

  // √âtats pour la transcription OpenAI
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [transcriptionStatus, setTranscriptionStatus] = useState('');
  const [transcriptionProgress, setTranscriptionProgress] = useState(0);
  const [analysisResult, setAnalysisResult] = useState(null);

  const loadNotes = async () => {
    try {
      const { data, error, status } = await supabase
        .from('notes')
        .select('*')
        .eq('project_id', projectId)
        .order('created_at', { ascending: false });
      
      if (error) {
        console.error('Erreur chargement notes:', status, error.message);
        Alert.alert('Erreur', 'Impossible de charger les notes');
        return;
      }
      setItems(data || []);
    } catch (err) {
      console.error('Exception chargement notes:', err);
      Alert.alert('Erreur', 'Erreur lors du chargement des notes');
    }
  };

  useEffect(() => {
    loadNotes();
    return () => {
      if (soundRef.current) {
        soundRef.current.unloadAsync();
      }
    };
  }, [projectId]);

  const startRecording = async () => {
    try {
      console.log('[VoiceRecorder] Demande de permission micro...');
      const { status: audioStatus } = await Audio.requestPermissionsAsync();
      console.log('[VoiceRecorder] Permission audio status:', audioStatus);
      
      if (audioStatus !== 'granted') {
        Alert.alert('Micro refus√©', 'Active le micro dans les r√©glages.');
        return;
      }

      console.log('[VoiceRecorder] Configuration du mode audio...');
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });

      console.log('[VoiceRecorder] Cr√©ation de l\'enregistrement...');
      const recording = new Audio.Recording();

      await recording.prepareToRecordAsync(
        Audio.RecordingOptionsPresets.HIGH_QUALITY
      );

      console.log('[VoiceRecorder] D√©marrage de l\'enregistrement...');
      await recording.startAsync();
      setRecording(recording);

      setRecordUri(null);
      setDurationMs(0);
      setTranscription('');
      setAnalysisResult(null);
      setTranscriptionStatus('');
      setTranscriptionProgress(0);

      logger.success('VoiceRecorder', 'Enregistrement d√©marr√©');

    } catch (e) {
      logger.error('VoiceRecorder', 'Erreur d√©marrage enregistrement', e);
      Alert.alert('Erreur', e?.message || 'Impossible de d√©marrer.');
    }
  };

  const stopRecording = async () => {
    try {
      if (!recording) {
        console.warn('[VoiceRecorder] Aucun enregistrement en cours');
        return;
      }

      console.log('[VoiceRecorder] Arr√™t de l\'enregistrement...');
      
      await recording.stopAndUnloadAsync();
      const uri = recording.getURI();
      console.log('[VoiceRecorder] URI obtenue:', uri);

      const status = await recording.getStatusAsync();
      const duration = status?.durationMillis || 0;
      const durationSeconds = Math.round(duration / 1000);

      setDurationMs(duration);

      // V√©rifier dur√©e minimale (2 secondes)
      if (duration < 2000) {
        Alert.alert(
          'Enregistrement trop court',
          `L'enregistrement ne fait que ${durationSeconds} seconde(s).\n\nEnregistrez au moins 2 secondes pour une bonne transcription.`,
          [
            { text: 'R√©essayer', onPress: () => setRecording(null) },
            { text: 'Garder quand m√™me', onPress: () => setRecordUri(uri) }
          ]
        );
        setRecording(null);
        return;
      }

      console.log(`[VoiceRecorder] Dur√©e enregistrement: ${durationSeconds}s (${duration}ms)`);

      setRecording(null);
      setRecordUri(uri);

      logger.success('VoiceRecorder', `Enregistrement arr√™t√© - Dur√©e: ${durationSeconds}s`);
    } catch (e) {
      logger.error('VoiceRecorder', 'Erreur arr√™t enregistrement', e);
      Alert.alert('Erreur', e?.message || 'Stop impossible.');
    }
  };

  const uploadAndSave = async () => {
    if (!recordUri) return Alert.alert('Aucun enregistrement', 'Enregistre d\'abord.');

    // V√©rifier les s√©lections dans le store
    const { currentClient, currentProject } = useAppStore.getState();
    if (!currentProject?.id || !currentClient?.id) {
      Alert.alert('S√©lection manquante', 'S√©lectionne d\'abord un client et un chantier');
      return;
    }

    try {
      setUploading(true);

      console.log('[VoiceRecorder] Upload du fichier:', recordUri);

      const resp = await fetch(recordUri);
      const arrayBuffer = await resp.arrayBuffer();
      const bytes = new Uint8Array(arrayBuffer);
      const fileName = `rec_${projectId}_${Date.now()}.m4a`;

      const { data: up, error: upErr } = await supabase
        .storage
        .from('voices')
        .upload(fileName, bytes, { contentType: 'audio/m4a', upsert: false });
      if (upErr) throw upErr;

      logger.success('VoiceRecorder', `Upload r√©ussi - Fichier: ${fileName}`, { projectId, clientId: currentClient.id });

      // √âTAPE 1 : Transcription avec OpenAI Whisper
      setIsTranscribing(true);
      setTranscriptionStatus('üé§ Transcription en cours...');
      setTranscriptionProgress(30);

      let transcribedText = '';
      let analysis = null;

      try {
        transcribedText = await transcribeAudio(recordUri);
        console.log('[VoiceRecorder] Transcription:', transcribedText);
        
        setTranscriptionProgress(60);
        setTranscriptionStatus('üß† Analyse de la note...');
        
        // √âTAPE 2 : Analyse de la note avec GPT
        if (transcribedText && transcribedText.trim()) {
          analysis = await analyzeNote(transcribedText);
          console.log('[VoiceRecorder] Analyse:', analysis);
          setAnalysisResult(analysis);
        }
        
        setTranscriptionProgress(100);
        setTranscriptionStatus('‚úÖ Termin√© !');
        
        setTranscription(transcribedText);
        
      } catch (transcribeError) {
        console.error('[VoiceRecorder] Erreur transcription/analyse:', transcribeError);
        
        const errorInfo = handleAPIError(transcribeError, 'VoiceRecorder');
        
        // Continuer quand m√™me avec une transcription vide
        transcribedText = '';
        analysis = {
          type: 'note_perso',
          note: 'Transcription √©chou√©e - √Ä compl√©ter manuellement'
        };
        
        Alert.alert(
          errorInfo.title || 'Erreur de transcription',
          errorInfo.message || 'L\'audio a √©t√© sauvegard√© mais la transcription a √©chou√©. Vous pouvez r√©essayer plus tard ou √©diter manuellement.',
          errorInfo.retry ? [
            { text: 'OK' },
            { text: 'R√©essayer', onPress: () => {
              setTimeout(() => uploadAndSave(), 500);
            }}
          ] : [{ text: 'OK' }]
        );
      } finally {
        setIsTranscribing(false);
        setTranscriptionStatus('');
        setTranscriptionProgress(0);
      }

      // √âTAPE 3 : Sauvegarder la note vocale
      const { data: { user } } = await supabase.auth.getUser();
      
      const noteData = {
        project_id: currentProject.id,
        client_id: currentClient.id,
        user_id: user?.id,
        type: 'voice',
        storage_path: up?.path || fileName,
        transcription: transcribedText || null,
        analysis_data: analysis ? JSON.stringify(analysis) : null,
      };

      const { error: insErr } = await supabase.from('notes').insert([noteData]);

      if (insErr) {
        logger.error('VoiceRecorder', 'Erreur insertion DB', insErr);
        
        // V√©rifier si c'est une erreur de colonne manquante
        const errorMessage = insErr.message || '';
        if (errorMessage.includes('transcription') || errorMessage.includes('analysis_data')) {
          const missingColumns = [];
          if (errorMessage.includes('transcription')) missingColumns.push('transcription');
          if (errorMessage.includes('analysis_data')) missingColumns.push('analysis_data');
          
          throw new Error(
            `Colonnes manquantes dans Supabase: ${missingColumns.join(', ')}. ` +
            `Ex√©cutez la migration: supabase/migrations_notes_transcription.sql`
          );
        }
        
        // Autre erreur
        throw new Error(`Erreur lors de l'enregistrement: ${errorMessage}`);
      }
      
      logger.success('VoiceRecorder', 'Note sauvegard√©e en base', { noteId: noteData.project_id });

      setRecordUri(null);
      setDurationMs(0);
      setTranscription('');
      setAnalysisResult(null);

      await loadNotes();

      // √âTAPE 4 : G√©n√©rer un devis automatiquement si prestation d√©tect√©e
      let alertTitle = '‚úÖ Note vocale envoy√©e.';
      let alertMessage = transcribedText ? `Transcription:\n${transcribedText}` : '';
      
      if (analysis && analysis.type === 'prestation' && transcribedText && transcribedText.trim()) {
        logger.info('VoiceRecorder', 'Prestation d√©tect√©e, g√©n√©ration devis automatique');
        
        try {
          // Utiliser le syst√®me existant de g√©n√©ration de devis
          const quoteData = generateQuoteFromTranscription(transcribedText, currentProject.id, currentClient.id, 20);
          
          if (quoteData && quoteData.services && quoteData.services.length > 0) {
            logger.success('VoiceRecorder', `Prestations d√©tect√©es: ${quoteData.services.length}`, quoteData);
            
            const devisCreated = await insertAutoQuote(
              currentProject.id,
              currentClient.id,
              quoteData.services,
              quoteData.totals,
              transcribedText,
              20
            );
            
            if (devisCreated) {
              logger.success('VoiceRecorder', 'Devis automatique g√©n√©r√©', { numero: devisCreated.numero, totals: quoteData.totals });
              alertTitle = 'ü§ñ Devis automatique g√©n√©r√© ‚úÖ.';
              alertMessage = 
                `Note vocale envoy√©e ‚úÖ.\n\n` +
                `üéØ ${quoteData.services.length} prestation(s) d√©tect√©e(s)\n\n` +
                `Total HT: ${quoteData.totals.totalHT.toFixed(2)} ‚Ç¨\n` +
                `Total TTC: ${quoteData.totals.totalTTC.toFixed(2)} ‚Ç¨\n\n` +
                `üìÑ Devis ${devisCreated.numero} cr√©√©.`;
            }
          }
        } catch (quoteError) {
          console.error('[VoiceRecorder] Erreur g√©n√©ration devis:', quoteError);
          // Ne pas bloquer, juste logger l'erreur
        }
      } else if (analysis && analysis.type === 'client_info') {
        alertTitle = '‚ÑπÔ∏è Info client enregistr√©e';
        alertMessage = `Note vocale sauvegard√©e.\n\nInfo client: ${analysis.info || transcribedText}`;
      }

      Alert.alert(alertTitle, alertMessage);

    } catch (e) {
      logger.error('VoiceRecorder', 'Erreur uploadAndSave', e);
      
      // Message d'erreur plus clair pour l'utilisateur
      let errorMessage = e?.message || 'Upload impossible.';
      if (errorMessage.includes('Colonnes manquantes')) {
        errorMessage = 'Erreur de configuration base de donn√©es. Contactez le support.';
      }
      
      showError(errorMessage);
      
      // Ne pas perdre l'enregistrement si c'est juste une erreur DB
      // L'audio a √©t√© upload√©, on peut r√©essayer l'insertion plus tard
      if (recordUri && !errorMessage.includes('Upload')) {
        logger.warn('VoiceRecorder', 'Audio upload√© mais insertion DB √©chou√©e', { recordUri });
      }
    } finally {
      setUploading(false);
      setIsTranscribing(false);
      setTranscriptionStatus('');
      setTranscriptionProgress(0);
    }
  };

  const play = async (item) => {
    try {
      if (soundRef.current) {
        await soundRef.current.unloadAsync();
        soundRef.current = null;
        setPlayingId(null);
      }

      const path = item.storage_path || item.file_path;
      if (!path) {
        throw new Error('Aucun chemin de fichier trouv√©');
      }
      let { data: pub } = supabase.storage.from('voices').getPublicUrl(path);
      let url = pub?.publicUrl;
      if (!url) {
        const { data: signed } = await supabase.storage
          .from('voices')
          .createSignedUrl(path, 3600);
        url = signed?.signedUrl;
      }

      const { sound } = await Audio.Sound.createAsync({ uri: url });
      soundRef.current = sound;
      setPlayingId(item.id);
      await sound.playAsync();

      sound.setOnPlaybackStatusUpdate((s) => {
        if (s.didJustFinish) {
          setPlayingId(null);
          sound.unloadAsync();
          soundRef.current = null;
        }
      });
    } catch (e) {
      console.error('[VoiceRecorder] Erreur play:', e);
      Alert.alert('Lecture impossible', e?.message || 'Erreur de lecture.');
    }
  };

  const saveEdit = async (id) => {
    try {
      const { error } = await supabase
        .from('notes')
        .update({ transcription: editText })
        .eq('id', id);
      if (error) throw error;
      setEditingId(null);
      setEditText('');
      await loadNotes();
      Alert.alert('OK', 'Note modifi√©e ‚úÖ');
    } catch (e) {
      Alert.alert('Erreur', e.message || 'Modification impossible');
    }
  };

  const Item = ({ item }) => {
    const isEditing = editingId === item.id;
    let itemAnalysis = null;
    try {
      if (item.analysis_data) {
        itemAnalysis = JSON.parse(item.analysis_data);
      }
    } catch (e) {
      // Ignorer les erreurs de parsing
    }
    
    return (
      <View style={styles.itemCard}>
        <View style={styles.row}>
          <Text style={styles.durationText}>
            {Math.round((item.duration_ms || 0) / 1000)}s
          </Text>
          <TouchableOpacity onPress={() => play(item)} style={styles.playBtn}>
            <Text style={styles.playBtnText}>
              {playingId === item.id ? '‚è∏Ô∏è Pause' : '‚ñ∂Ô∏è Lire'}
            </Text>
          </TouchableOpacity>
        </View>
        
        {item.transcription ? (
          <View style={styles.transcriptionBox}>
            {isEditing ? (
              <>
                <TextInput
                  style={styles.editInput}
                  value={editText}
                  onChangeText={setEditText}
                  multiline
                  autoFocus
                  placeholderTextColor="#9CA3AF"
                />
                <View style={styles.editActions}>
                  <TouchableOpacity onPress={() => saveEdit(item.id)} style={styles.saveBtn}>
                    <Text style={styles.saveBtnText}>üíæ Sauvegarder</Text>
                  </TouchableOpacity>
                  <TouchableOpacity onPress={() => { setEditingId(null); setEditText(''); }} style={styles.cancelBtn}>
                    <Text style={styles.cancelBtnText}>‚ùå Annuler</Text>
                  </TouchableOpacity>
                </View>
              </>
            ) : (
              <>
                {itemAnalysis && (
                  <View style={styles.analysisBadge}>
                    <Text style={styles.analysisBadgeText}>
                      {itemAnalysis.type === 'prestation' ? '‚úÖ Prestation' : 
                       itemAnalysis.type === 'client_info' ? '‚ÑπÔ∏è Info client' : 
                       'üìù Note perso'}
                    </Text>
                  </View>
                )}
                <Text style={styles.transcriptionDisplay}>{item.transcription}</Text>
                <View style={styles.editActions}>
                  <TouchableOpacity onPress={() => { setEditingId(item.id); setEditText(item.transcription); }} style={styles.editBtn}>
                    <Text style={styles.editBtnText}>‚úèÔ∏è Modifier</Text>
                  </TouchableOpacity>
                  <TouchableOpacity 
                    onPress={async () => {
                      const { currentClient, currentProject } = useAppStore.getState();
                      if (!currentProject?.id || !currentClient?.id) {
                        Alert.alert('S√©lection manquante', 'S√©lectionne d\'abord un client et un chantier');
                        return;
                      }

                      try {
                        const quoteData = generateQuoteFromTranscription(
                          item.transcription,
                          currentProject.id,
                          currentClient.id,
                          20
                        );

                        if (quoteData && quoteData.services && quoteData.services.length > 0) {
                          const devis = await insertAutoQuote(
                            currentProject.id,
                            currentClient.id,
                            quoteData.services,
                            quoteData.totals,
                            item.transcription,
                            20
                          );

                          if (devis) {
                            Alert.alert(
                              'üéØ Devis automatique g√©n√©r√© ‚úÖ',
                              `${quoteData.services.length} prestation(s) d√©tect√©e(s)\n\n` +
                              `Total HT: ${quoteData.totals.totalHT.toFixed(2)} ‚Ç¨\n` +
                              `Total TTC: ${quoteData.totals.totalTTC.toFixed(2)} ‚Ç¨\n\n` +
                              `üìÑ Devis ${devis.numero} cr√©√©.`
                            );
                          } else {
                            Alert.alert('Erreur', 'Impossible de cr√©er le devis');
                          }
                        } else {
                          Alert.alert('‚ÑπÔ∏è Info', 'Aucune prestation d√©tect√©e dans cette transcription.');
                        }
                      } catch (err) {
                        console.error('[VoiceRecorder] Erreur g√©n√©ration devis:', err);
                        Alert.alert('Erreur', err.message || 'G√©n√©ration √©chou√©e');
                      }
                    }}
                    style={styles.aiButton}
                  >
                    <Text style={styles.aiButtonText}>üß† G√©n√©rer Devis IA</Text>
                  </TouchableOpacity>
                </View>
              </>
            )}
          </View>
        ) : (
          <Text style={styles.noTranscript}>Pas de transcription</Text>
        )}
      </View>
    );
  };

  return (
    <View style={styles.box}>
      <View style={styles.titleRow}>
        <Text style={styles.title}>Note vocale</Text>
        <View style={styles.whisperBadge}>
          <Text style={styles.whisperBadgeText}>üé§ Transcription IA</Text>
        </View>
      </View>

      <View style={styles.row}>
        {!recording ? (
          <TouchableOpacity onPress={startRecording} style={styles.primary}>
            <Text style={styles.primaryText}>üéôÔ∏è Enregistrer</Text>
          </TouchableOpacity>
        ) : (
          <TouchableOpacity onPress={stopRecording} style={[styles.primary, { backgroundColor: '#DC2626' }]}>
            <Text style={styles.primaryText}>‚èπÔ∏è Stop</Text>
          </TouchableOpacity>
        )}

        <TouchableOpacity
          onPress={uploadAndSave}
          style={[styles.secondary, !recordUri && { opacity: 0.5 }]}
          disabled={!recordUri || uploading || isTranscribing}
        >
          <Text style={styles.secondaryText}>
            {isTranscribing ? 'üé§ Transcription‚Ä¶' : uploading ? 'Envoi‚Ä¶' : '‚òÅÔ∏è Envoyer'}
          </Text>
        </TouchableOpacity>
      </View>

      {/* Overlay de transcription en cours */}
      {isTranscribing && (
        <View style={styles.transcriptionOverlay}>
          <ActivityIndicator size="large" color="#4CAF50" />
          <Text style={styles.transcriptionStatus}>
            {transcriptionStatus}
          </Text>
          <View style={styles.progressBar}>
            <View 
              style={[
                styles.progressFill, 
                { width: `${transcriptionProgress}%` }
              ]} 
            />
          </View>
        </View>
      )}

      {recordUri && !isTranscribing && (
        <View style={styles.infoContainer}>
          <Text style={styles.infoText}>
            Dur√©e: {Math.round(durationMs / 1000)}s ‚Ä¢ Pr√™t pour transcription
          </Text>
        </View>
      )}
      
      {transcription && !isTranscribing && (
        <View style={styles.transcriptionContainer}>
          <Text style={styles.transcriptionLabel}>Transcription:</Text>
          <Text style={styles.transcriptionText}>{transcription}</Text>
          {analysisResult && (
            <View style={styles.analysisContainer}>
              <Text style={styles.analysisLabel}>
                Type: {analysisResult.type === 'prestation' ? '‚úÖ Prestation' : 
                       analysisResult.type === 'client_info' ? '‚ÑπÔ∏è Info client' : 
                       'üìù Note perso'}
              </Text>
            </View>
          )}
        </View>
      )}

      <FlatList
        data={items}
        keyExtractor={(it) => String(it.id)}
        renderItem={({ item }) => <Item item={item} />}
        ListEmptyComponent={<Text style={styles.emptyText}>Aucune note pour ce chantier.</Text>}
      />
    </View>
  );
}

const styles = StyleSheet.create({
  box: { marginTop: 8, paddingTop: 8, borderTopWidth: 1, borderColor: '#2A2E35' },
  title: { fontWeight: '800', marginBottom: 6, color: '#EAEAEA', fontSize: 16 },
  row: { flexDirection: 'row', alignItems: 'center', justifyContent: 'space-between', marginBottom: 8 },
  primary: { backgroundColor: '#1D4ED8', paddingVertical: 8, paddingHorizontal: 12, borderRadius: 10 },
  primaryText: { color: '#fff', fontWeight: '700' },
  secondary: { backgroundColor: '#2A2E35', paddingVertical: 8, paddingHorizontal: 12, borderRadius: 10 },
  secondaryText: { color: '#EAEAEA', fontWeight: '700' },
  playBtn: { paddingVertical: 6, paddingHorizontal: 10, backgroundColor: '#1E3A8A', borderRadius: 8 },
  playBtnText: { color: '#93C5FD', fontWeight: '700' },
  transcriptionContainer: { marginBottom: 12, padding: 12, backgroundColor: '#1A1D22', borderRadius: 8, borderLeftWidth: 3, borderLeftColor: '#1D4ED8' },
  transcriptionLabel: { fontWeight: '700', marginBottom: 4, color: '#EAEAEA' },
  transcriptionText: { color: '#D1D5DB', fontSize: 14, lineHeight: 20 },
  itemCard: { marginBottom: 12, padding: 12, backgroundColor: '#1A1D22', borderRadius: 8, borderWidth: 1, borderColor: '#2A2E35' },
  transcriptionBox: { marginTop: 8 },
  transcriptionDisplay: { color: '#D1D5DB', fontSize: 14, lineHeight: 20, marginBottom: 8 },
  editInput: { borderWidth: 1, borderColor: '#374151', borderRadius: 8, padding: 8, minHeight: 80, backgroundColor: '#0F1115', color: '#EAEAEA' },
  editActions: { flexDirection: 'row', gap: 8, marginTop: 8 },
  editBtn: { paddingVertical: 6, paddingHorizontal: 10, backgroundColor: '#1E3A8A', borderRadius: 8 },
  editBtnText: { color: '#93C5FD', fontWeight: '700', fontSize: 12 },
  saveBtn: { paddingVertical: 6, paddingHorizontal: 10, backgroundColor: '#10B981', borderRadius: 8 },
  saveBtnText: { color: '#fff', fontWeight: '700', fontSize: 12 },
  cancelBtn: { paddingVertical: 6, paddingHorizontal: 10, backgroundColor: '#DC2626', borderRadius: 8 },
  cancelBtnText: { color: '#fff', fontWeight: '700', fontSize: 12 },
  noTranscript: { color: '#6B7280', fontSize: 12, fontStyle: 'italic' },
  aiButton: { paddingVertical: 6, paddingHorizontal: 10, backgroundColor: '#10B981', borderRadius: 8 },
  aiButtonText: { color: '#fff', fontWeight: '700', fontSize: 12 },
  durationText: { fontWeight: '700', color: '#D1D5DB' },
  emptyText: { color: '#6B7280', textAlign: 'center', marginTop: 20 },
  infoContainer: { marginBottom: 8, padding: 8, backgroundColor: '#1A1D22', borderRadius: 6 },
  infoText: { color: '#9CA3AF', fontSize: 12, textAlign: 'center' },
  titleRow: { flexDirection: 'row', alignItems: 'center', justifyContent: 'space-between', marginBottom: 6 },
  whisperBadge: { backgroundColor: '#10B981', paddingHorizontal: 8, paddingVertical: 4, borderRadius: 6 },
  whisperBadgeText: { color: '#fff', fontSize: 11, fontWeight: '700' },
  transcriptionOverlay: {
    position: 'absolute',
    top: 0,
    left: 0,
    right: 0,
    bottom: 0,
    backgroundColor: 'rgba(0, 0, 0, 0.85)',
    justifyContent: 'center',
    alignItems: 'center',
    zIndex: 1000,
    borderRadius: 10,
  },
  transcriptionStatus: {
    color: '#fff',
    fontSize: 16,
    marginTop: 20,
    marginBottom: 10,
    fontWeight: '600',
  },
  progressBar: {
    width: '80%',
    height: 4,
    backgroundColor: 'rgba(255, 255, 255, 0.3)',
    borderRadius: 2,
    overflow: 'hidden',
    marginTop: 10,
  },
  progressFill: {
    height: '100%',
    backgroundColor: '#4CAF50',
  },
  analysisContainer: {
    marginTop: 8,
    padding: 8,
    backgroundColor: 'rgba(16, 185, 129, 0.1)',
    borderRadius: 6,
  },
  analysisLabel: {
    color: '#10B981',
    fontSize: 12,
    fontWeight: '600',
  },
  analysisBadge: {
    alignSelf: 'flex-start',
    backgroundColor: 'rgba(16, 185, 129, 0.2)',
    paddingHorizontal: 8,
    paddingVertical: 4,
    borderRadius: 6,
    marginBottom: 8,
  },
  analysisBadgeText: {
    color: '#10B981',
    fontSize: 11,
    fontWeight: '600',
  },
});
